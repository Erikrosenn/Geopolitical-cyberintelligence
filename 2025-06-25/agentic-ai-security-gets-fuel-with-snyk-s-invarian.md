---
title: "Agentic AI Security Gets Fuel With Snyk's Invariant Labs Buy"
date: 2025-06-25
source: https://www.govinfosecurity.com/agentic-ai-security-gets-fuel-snyks-invariant-labs-buy-a-28789
publisher: govinfosecurity
tags: [cyber, geopolitics]
---

## TL;DR

Agentic AI

Snyk bought a Swiss AI security research startup led by a doctorate in computer science to secure new AI workflows and protocols like MCP See Also: How Agentic AI Presents New Identity Security Challenges

The Boston-based developer security firm said its purchase of Zurich-based Invariant Labs will influence next-gen capabilities such as red teaming of LLM-agent interactions and continuous testing of protocols like MCP, according to Chief Innovation Officer Manoj Nair He said the acquisition will give enterprises visibility into their AI component usage, uncover hidden risks, and ensure proactive security governance

## Full Article

Agentic AI

Snyk bought a Swiss AI security research startup led by a doctorate in computer science to secure new AI workflows and protocols like MCP.

See Also: How Agentic AI Presents New Identity Security Challenges

The Boston-based developer security firm said its purchase of Zurich-based Invariant Labs will influence next-gen capabilities such as red teaming of LLM-agent interactions and continuous testing of protocols like MCP, according to Chief Innovation Officer Manoj Nair. He said the acquisition will give enterprises visibility into their AI component usage, uncover hidden risks, and ensure proactive security governance.

"We've rarely had so much competition on an acquisition," Nair told Information Security Media Group. "They had inbounds and interest from trillion-dollar-plus market cap companies. And for them, partly knowing what Snyk was able to do with research, find folks like them, but also the Snyk platform - it really complements what they do."

Invariant Labs, founded in 2024, employs approximately 10 people, and hasn't disclosed any outside funding. The company has been led since its inception by Marc Fischer, who spent more than a decade getting a bachelor's degree, master's degree and PhD in computer science at ETH Zurich. All Invariant employees remained with Snyk after the acquisition, which recently closed, according to Nair (see: Snyk Acquires Probely to Strengthen API Security for AI Apps)

While many research organizations have focused on foundational LLMs, Nair said few have ventured into the security implications of agentic AI, particularly when it comes to tool poisoning and model-context protocol vulnerabilities. Invariant's research pedigree, rooted in ETH Zurich—the same group behind Snyk’s previous DeepCode acquisition—played a pivotal role in establishing trust and familiarity.

"They're able to test MCP and all these new agents," Nair said. "We're able to find where it is in code. So you can start seeing the synergy and the dots there that are very complementary."

Nair said that 90% of Snyk’s strategic design partners are already engaged in deploying or developing AI agents. The agents need real-time runtime visibility, new forms of red teaming, and policy enforcement mechanisms to manage emerging risks. Invariant Labs’ work in understanding and securing these behaviors is central to Snyk’s mission of safeguarding AI-native software in production environments.

"AI apps are not like anything else that was known to software," Nair said. "In fact, it breaks the rules of software. In software, you put in an input, and it produces an output." But with an LLM, "every time you give it the same context and input, it could produce something else."

Snyk can use its AI Bill of Materials to detect the presence of agents, LLMs and protocols such as MCP across customer codebases. This visibility helps make Invariant’s tools more targeted and effective. Nair said the integration plan is to combine Snyk Code’s static analysis with Invariant’s dynamic traffic tracing and threat identification, enabling real-time enforcement of security policies across agentic systems.

"It takes years, sometimes, in an enterprise to get to that level of deployment," Nair said. "Now, you're just turning it on with the flip of a switch. That's not something any startup, or even mid-sized company, can get. The fact that it can detect en masse across our customer base and just feed that context is a pretty innovative set of capabilities we've been able to do without changing the engine."

While MCP - a framework that allows agents to interact with local and external data sources through LLMs - increases functionality, Nair said, it also introduces vulnerabilities, as evidenced by a serious issue discovered by Invariant in GitHub’s implementation. Invariant’s role in exposing flaws and defining “toxic agent flows” will be critical to improving MCP’s adoption in a secure manner, Nair said.

"Understanding what good flows look like and bad flows look like is critical to deploy and use MCP properly," Nair said.

The contextual data from Snyk's AI BOM will help Invariant’s tools operate at scale and with precision, Nair said. Rather than needing manual codebase identification for testing, Invariant can rely on AI BOM insights to pinpoint where and what to test. Snyk is also developing advanced red teaming capabilities that simulate attacks on AI-native apps, covering both the agent logic and its interactions with models.

"There could be a SQL injection attack happening just because somebody wrote a malicious agent and it's trying to inject that into the LLM," Nair said. "And Snyk Code detects it very well."

Feedback from Snyk's strategic design partners will shape the development of new capabilities, including those arising from the Invariant acquisition. Early versions of integrated features will be tested in these environments over the next three-to-four months, with a broader rollout expected by year-end. These partnerships help Snyk validate assumptions, uncover usability challenges and prioritize features.

"The actual agent and LLM interaction and that non-determinism give us visibility," Nair said. "Use that visibility to set policy. 'Snyk, you're already on the side where you're setting policy, but you need to bring this runtime context into setting policy.' Those are the kinds of things we're being asked to bring as part of the Snyk AI Trust platform."